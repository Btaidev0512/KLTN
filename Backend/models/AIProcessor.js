// ðŸ¤– AI PROCESSOR MODEL
// Handles AI logic, intent recognition, and response generation

const db = require('../config/database');
const OpenAI = require('openai');
const natural = require('natural');
const sentiment = require('sentiment');
const ChatMessage = require('./ChatMessage');
const ChatSession = require('./ChatSession');

// Initialize OpenAI
const openai = process.env.OPENAI_API_KEY ? new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
}) : null;

// Initialize NLP tools
const stemmer = natural.PorterStemmer;
const tokenizer = new natural.WordTokenizer();
const sentimentAnalyzer = new sentiment();

class AIProcessor {
    
    // Process user message and generate AI response
    static async processMessage(conversationId, userMessage, sessionId) {
        try {
            const startTime = Date.now();
            console.log(`ðŸ¤– Processing message: "${userMessage.substring(0, 50)}..."`);            
            // Step 1: Analyze intent
            const intent = await this.analyzeIntent(userMessage);
            console.log(`ðŸŽ¯ Intent detected: ${intent.name} (confidence: ${intent.confidence})`);            
            // Step 2: Get conversation context
            const context = await this.getConversationContext(conversationId, sessionId);
            
            // Step 3: Check for e-commerce specific actions
            const ecommerceAction = await this.checkEcommerceAction(userMessage, intent);
            
            // Step 4: Generate AI response
            const response = await this.generateResponse({
                userMessage,
                intent,
                context,
                ecommerceAction,
                conversationId,
                sessionId
            });
            
            const responseTime = Date.now() - startTime;
            
            // Step 5: Save AI response to database
            const aiMessage = await ChatMessage.addMessage(
                conversationId,
                'ai',
                response.text,
                response.type || 'text',
                response.metadata || null,
                {
                    confidence: intent.confidence,
                    intent: intent.name,
                    responseTime
                }
            );
            
            // Step 6: Update context
            await this.updateConversationContext(sessionId, {
                lastIntent: intent.name,
                lastUserMessage: userMessage,
                lastAIResponse: response.text,
                messageCount: (context.messageCount || 0) + 1
            });
            
            console.log(`âœ… AI response generated in ${responseTime}ms`);
            
            return {
                message: aiMessage,
                intent: intent.name,
                confidence: intent.confidence,
                responseTime,
                ecommerceAction: ecommerceAction || null
            };
            
        } catch (error) {
            console.error('âŒ AI processing error:', error);
            
            // Fallback response
            const fallbackMessage = await ChatMessage.addMessage(
                conversationId,
                'ai',
                'Xin lá»—i, tÃ´i khÃ´ng hiá»ƒu cÃ¢u há»i cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ nÃ³i rÃµ hÆ¡n khÃ´ng? Hoáº·c hÃ£y thá»­ nhá»¯ng gá»£i Ã½ sau:',
                'text',
                { fallback: true, error: error.message }
            );
            
            return {
                message: fallbackMessage,
                intent: 'unknown',
                confidence: 0,
                responseTime: 0,
                error: true
            };
        }
    }
    
    // Analyze user intent using keyword matching and NLP
    static async analyzeIntent(userMessage) {
        try {
            const message = userMessage.toLowerCase().trim();
            const tokens = tokenizer.tokenize(message);
            const stems = tokens.map(token => stemmer.stem(token));
            
            // Get all active intents from database
            const [intents] = await db.execute(`
                SELECT * FROM ai_intents 
                WHERE is_active = TRUE 
                ORDER BY priority_level ASC
            `);
            
            let bestMatch = {
                name: 'general',
                confidence: 0.3,
                template: 'TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?'
            };
            
            // Check each intent for keyword matches
            for (const intent of intents) {
                const keywords = intent.keywords.toLowerCase().split(',').map(k => k.trim());
                let matchScore = 0;
                let matchCount = 0;
                
                for (const keyword of keywords) {
                    if (message.includes(keyword)) {
                        matchScore += 1;
                        matchCount++;
                    }
                    
                    // Check stemmed versions
                    const keywordStems = tokenizer.tokenize(keyword).map(t => stemmer.stem(t));
                    for (const stem of keywordStems) {
                        if (stems.includes(stem)) {
                            matchScore += 0.7;
                            matchCount++;
                        }
                    }
                }
                
                // Calculate confidence based on matches
                const confidence = Math.min(matchScore / keywords.length, 1.0);
                
                if (confidence > bestMatch.confidence && confidence >= intent.confidence_threshold) {
                    bestMatch = {
                        name: intent.intent_name,
                        confidence: parseFloat(confidence.toFixed(2)),
                        template: intent.response_template,
                        category: intent.category
                    };
                }
            }
            
            // Update intent usage count
            if (bestMatch.name !== 'general') {
                await db.execute(`
                    UPDATE ai_intents 
                    SET usage_count = usage_count + 1 
                    WHERE intent_name = ?
                `, [bestMatch.name]);
            }
            
            return bestMatch;
            
        } catch (error) {
            console.error('âŒ Intent analysis error:', error);
            return {
                name: 'general',
                confidence: 0.1,
                template: 'TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?'
            };
        }
    }
    
    // Get conversation context
    static async getConversationContext(conversationId, sessionId) {
        try {
            // Get recent messages for context
            const recentMessages = await ChatMessage.getRecentContext(conversationId, 5);
            
            // Get session context
            const session = await ChatSession.getSession(sessionId);
            const sessionContext = session ? session.conversation_context : {};
            
            return {
                recentMessages,
                sessionContext,
                messageCount: recentMessages.length
            };
        } catch (error) {
            console.error('âŒ Error getting context:', error);
            return {
                recentMessages: [],
                sessionContext: {},
                messageCount: 0
            };
        }
    }
    
    // Check for e-commerce specific actions
    static async checkEcommerceAction(userMessage, intent) {
        try {
            const message = userMessage.toLowerCase();
            
            // Product search patterns
            const productPatterns = [
                /tÃ¬m sáº£n pháº©m (.+)/i,
                /mua (.+)/i,
                /cÃ³ (.+) khÃ´ng/i,
                /giÃ¡ (.+)/i
            ];
            
            // Order tracking patterns
            const orderPatterns = [
                /Ä‘Æ¡n hÃ ng (.+)/i,
                /mÃ£ Ä‘Æ¡n (.+)/i,
                /order (.+)/i,
                /tra cá»©u (.+)/i
            ];
            
            // Check for product search
            for (const pattern of productPatterns) {
                const match = message.match(pattern);
                if (match) {
                    return {
                        type: 'product_search',
                        query: match[1].trim(),
                        intent: intent.name
                    };
                }
            }
            
            // Check for order tracking
            for (const pattern of orderPatterns) {
                const match = message.match(pattern);
                if (match) {
                    return {
                        type: 'order_tracking',
                        orderId: match[1].trim(),
                        intent: intent.name
                    };
                }
            }
            
            return null;
        } catch (error) {
            console.error('âŒ E-commerce action check error:', error);
            return null;
        }
    }
    
    // Generate AI response
    static async generateResponse(data) {
        const { userMessage, intent, context, ecommerceAction, conversationId, sessionId } = data;
        
        try {
            // Handle e-commerce specific actions first
            if (ecommerceAction) {
                return await this.handleEcommerceAction(ecommerceAction, data);
            }
            
            // Use OpenAI if available
            if (openai && process.env.OPENAI_API_KEY) {
                return await this.generateOpenAIResponse(data);
            }
            
            // Fallback to template-based responses
            return await this.generateTemplateResponse(intent, context, userMessage);
            
        } catch (error) {
            console.error('âŒ Response generation error:', error);
            return {
                text: 'Xin lá»—i, tÃ´i gáº·p chÃºt váº¥n Ä‘á». Báº¡n cÃ³ thá»ƒ thá»­ láº¡i khÃ´ng?',
                type: 'text'
            };
        }
    }
    
    // Handle e-commerce specific actions
    static async handleEcommerceAction(action, data) {
        try {
            if (action.type === 'product_search') {
                return await this.handleProductSearch(action.query);
            }
            
            if (action.type === 'order_tracking') {
                return await this.handleOrderTracking(action.orderId, data.sessionId);
            }
            
            return {
                text: 'TÃ´i Ä‘Ã£ hiá»ƒu yÃªu cáº§u cá»§a báº¡n vÃ  Ä‘ang xá»­ lÃ½...',
                type: 'text'
            };
        } catch (error) {
            console.error('âŒ E-commerce action error:', error);
            return {
                text: 'Xin lá»—i, tÃ´i khÃ´ng thá»ƒ thá»±c hiá»‡n yÃªu cáº§u nÃ y lÃºc nÃ y.',
                type: 'text'
            };
        }
    }
    
    // Handle product search
    static async handleProductSearch(query) {
        try {
            // Search products using existing search system
            const [products] = await db.execute(`
                SELECT id, product_name, price, image_url, category_id, brand_id,
                       MATCH(product_name, description) AGAINST(? IN BOOLEAN MODE) as relevance
                FROM products 
                WHERE MATCH(product_name, description) AGAINST(? IN BOOLEAN MODE)
                AND is_active = TRUE
                ORDER BY relevance DESC
                LIMIT 5
            `, [query, query]);
            
            if (products.length === 0) {
                return {
                    text: `KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m nÃ o vá»›i tá»« khÃ³a "${query}". Báº¡n cÃ³ thá»ƒ thá»­ tÃ¬m vá»›i tá»« khÃ³a khÃ¡c khÃ´ng?`,
                    type: 'text'
                };
            }
            
            return {
                text: `TÃ´i Ä‘Ã£ tÃ¬m tháº¥y ${products.length} sáº£n pháº©m phÃ¹ há»£p vá»›i "${query}":`,
                type: 'product_card',
                metadata: {
                    products: products,
                    query: query
                }
            };
        } catch (error) {
            console.error('âŒ Product search error:', error);
            return {
                text: `Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tÃ¬m kiáº¿m sáº£n pháº©m "${query}" lÃºc nÃ y. Vui lÃ²ng thá»­ láº¡i sau.`,
                type: 'text'
            };
        }
    }
    
    // Handle order tracking
    static async handleOrderTracking(orderId, sessionId) {
        try {
            // Try to find order by ID first
            let [orders] = await db.execute(`
                SELECT o.*, u.email 
                FROM orders o
                LEFT JOIN users u ON o.user_id = u.id
                WHERE o.id = ? OR o.order_number = ?
            `, [orderId, orderId]);
            
            if (orders.length === 0) {
                // If not found, ask for email
                await ChatSession.addToContext(sessionId, 'pending_order_lookup', orderId);
                
                return {
                    text: `KhÃ´ng tÃ¬m tháº¥y Ä‘Æ¡n hÃ ng vá»›i mÃ£ "${orderId}". Báº¡n cÃ³ thá»ƒ cung cáº¥p email Ä‘áº·t hÃ ng khÃ´ng?`,
                    type: 'text'
                };
            }
            
            const order = orders[0];
            return {
                text: `ðŸ“¦ ThÃ´ng tin Ä‘Æ¡n hÃ ng #${order.id}:`,
                type: 'order_info',
                metadata: {
                    order: order,
                    orderId: orderId
                }
            };
            
        } catch (error) {
            console.error('âŒ Order tracking error:', error);
            return {
                text: `Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tra cá»©u Ä‘Æ¡n hÃ ng "${orderId}" lÃºc nÃ y.`,
                type: 'text'
            };
        }
    }
    
    // Generate OpenAI response
    static async generateOpenAIResponse(data) {
        try {
            const { userMessage, intent, context } = data;
            
            const systemPrompt = `Báº¡n lÃ  trá»£ lÃ½ AI cho website thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­. 
Báº¡n giÃºp khÃ¡ch hÃ ng vá»:
- TÃ¬m kiáº¿m sáº£n pháº©m
- Tra cá»©u Ä‘Æ¡n hÃ ng
- Há»— trá»£ thanh toÃ¡n
- Giáº£i Ä‘Ã¡p cÃ¢u há»i

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch.`;
            
            const messages = [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: userMessage }
            ];
            
            // Add context if available
            if (context.recentMessages && context.recentMessages.length > 0) {
                const contextStr = context.recentMessages
                    .map(msg => `${msg.sender_type}: ${msg.message_text}`)
                    .join('\n');
                messages.splice(1, 0, {
                    role: 'system', 
                    content: `Ngá»¯ cáº£nh cuá»™c há»™i thoáº¡i trÆ°á»›c:\n${contextStr}`
                });
            }
            
            const completion = await openai.chat.completions.create({
                model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
                messages: messages,
                max_tokens: parseInt(process.env.OPENAI_MAX_TOKENS || '500'),
                temperature: 0.7
            });
            
            const responseText = completion.choices[0].message.content.trim();
            
            return {
                text: responseText,
                type: 'text',
                metadata: {
                    openai_model: completion.model,
                    tokens_used: completion.usage?.total_tokens || 0
                }
            };
            
        } catch (error) {
            console.error('âŒ OpenAI response error:', error);
            throw error;
        }
    }
    
    // Generate template-based response
    static async generateTemplateResponse(intent, context, userMessage) {
        try {
            // Get quick replies for this intent
            const [quickReplies] = await db.execute(`
                SELECT title, message FROM chat_quick_replies 
                WHERE category = ? AND is_active = TRUE
                ORDER BY display_order ASC
                LIMIT 3
            `, [intent.category || 'support']);
            
            let responseText = intent.template || 'TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?';
            
            // Add personalization based on context
            if (context.messageCount > 5) {
                responseText = 'TÃ´i tháº¥y báº¡n cÃ³ nhiá»u cÃ¢u há»i. ' + responseText;
            }
            
            return {
                text: responseText,
                type: 'text',
                metadata: {
                    intent: intent.name,
                    quick_replies: quickReplies,
                    template_used: true
                }
            };
        } catch (error) {
            console.error('âŒ Template response error:', error);
            return {
                text: 'TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?',
                type: 'text'
            };
        }
    }
    
    // Update conversation context
    static async updateConversationContext(sessionId, updates) {
        try {
            const session = await ChatSession.getSession(sessionId);
            if (!session) return;
            
            const currentContext = session.conversation_context || {};
            const newContext = { ...currentContext, ...updates };
            
            await ChatSession.updateContext(sessionId, newContext);
        } catch (error) {
            console.error('âŒ Context update error:', error);
        }
    }
    
    // Analyze message sentiment
    static analyzeSentiment(text) {
        try {
            const result = sentimentAnalyzer.analyze(text);
            return {
                score: result.score,
                comparative: result.comparative,
                positive: result.positive,
                negative: result.negative,
                sentiment: result.score > 0 ? 'positive' : result.score < 0 ? 'negative' : 'neutral'
            };
        } catch (error) {
            console.error('âŒ Sentiment analysis error:', error);
            return { sentiment: 'neutral', score: 0 };
        }
    }
}

module.exports = AIProcessor;