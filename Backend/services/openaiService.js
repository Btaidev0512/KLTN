// ü§ñ OPENAI SERVICE
// Handles OpenAI API integration for chat responses

const OpenAI = require('openai');

// Initialize OpenAI client
const openai = process.env.OPENAI_API_KEY ? new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
}) : null;

// System prompts for different contexts
const SYSTEM_PROMPTS = {
    general: `B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán cho website th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ t·∫°i Vi·ªát Nam. 
B·∫°n gi√∫p kh√°ch h√†ng v·ªÅ:
- T√¨m ki·∫øm s·∫£n ph·∫©m
- Tra c·ª©u ƒë∆°n h√†ng  
- H·ªó tr·ª£ thanh to√°n
- Gi·∫£i ƒë√°p c√¢u h·ªèi v·ªÅ s·∫£n ph·∫©m v√† d·ªãch v·ª•

H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, th√¢n thi·ªán v√† h·ªØu √≠ch. S·ª≠ d·ª•ng emoji ƒë·ªÉ t·∫°o c·∫£m gi√°c th√¢n thi·ªán.`,
    
    product: `B·∫°n l√† chuy√™n vi√™n t∆∞ v·∫•n s·∫£n ph·∫©m cho c·ª≠a h√†ng online. 
Gi√∫p kh√°ch h√†ng:
- T√¨m s·∫£n ph·∫©m ph√π h·ª£p
- So s√°nh t√≠nh nƒÉng v√† gi√° c·∫£
- T∆∞ v·∫•n l·ª±a ch·ªçn
- Gi·∫£i th√≠ch th√¥ng s·ªë k·ªπ thu·∫≠t

Tr·∫£ l·ªùi chi ti·∫øt, chuy√™n nghi·ªáp nh∆∞ng d·ªÖ hi·ªÉu.`,
    
    order: `B·∫°n l√† nh√¢n vi√™n h·ªó tr·ª£ ƒë∆°n h√†ng. Gi√∫p kh√°ch h√†ng:
- Tra c·ª©u t√¨nh tr·∫°ng ƒë∆°n h√†ng
- Gi·∫£i th√≠ch quy tr√¨nh v·∫≠n chuy·ªÉn
- X·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ v·ªÅ ƒë∆°n h√†ng
- H∆∞·ªõng d·∫´n hu·ª∑ ƒë∆°n ho·∫∑c ƒë·ªïi tr·∫£

Lu√¥n ƒë·∫£m b·∫£o th√¥ng tin ch√≠nh x√°c v√† c·∫≠p nh·∫≠t.`,
    
    payment: `B·∫°n l√† chuy√™n vi√™n h·ªó tr·ª£ thanh to√°n. Gi√∫p kh√°ch h√†ng:
- H∆∞·ªõng d·∫´n c√°c ph∆∞∆°ng th·ª©c thanh to√°n
- Gi·∫£i quy·∫øt l·ªói thanh to√°n
- Gi·∫£i th√≠ch ph√≠ d·ªãch v·ª•
- H·ªó tr·ª£ ho√†n ti·ªÅn

Cung c·∫•p th√¥ng tin r√µ r√†ng v√† ƒë√°ng tin c·∫≠y.`
};

class OpenAIService {
    
    // Check if OpenAI is available
    static isAvailable() {
        return openai !== null && process.env.OPENAI_API_KEY;
    }
    
    // Generate chat completion
    static async generateResponse({
        userMessage,
        context = [],
        intent = 'general',
        maxTokens = 500,
        temperature = 0.7
    }) {
        try {
            if (!this.isAvailable()) {
                throw new Error('OpenAI API key not configured');
            }
            
            // Select appropriate system prompt
            const systemPrompt = SYSTEM_PROMPTS[intent] || SYSTEM_PROMPTS.general;
            
            // Build messages array
            const messages = [
                { role: 'system', content: systemPrompt }
            ];
            
            // Add context from previous messages
            if (context && context.length > 0) {
                const contextStr = context
                    .slice(-3) // Last 3 messages for context
                    .map(msg => `${msg.sender_type === 'user' ? 'Kh√°ch h√†ng' : 'B·∫°n'}: ${msg.message_text}`)
                    .join('\n');
                
                messages.push({
                    role: 'system',
                    content: `Ng·ªØ c·∫£nh cu·ªôc h·ªôi tho·∫°i g·∫ßn ƒë√¢y:\n${contextStr}`
                });
            }
            
            // Add current user message
            messages.push({
                role: 'user',
                content: userMessage
            });
            
            console.log('ü§ñ Calling OpenAI API...');
            
            // Call OpenAI
            const completion = await openai.chat.completions.create({
                model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
                messages: messages,
                max_tokens: maxTokens,
                temperature: temperature,
                top_p: 0.9,
                frequency_penalty: 0.3,
                presence_penalty: 0.3
            });
            
            const response = completion.choices[0].message.content.trim();
            
            console.log(`‚úÖ OpenAI response generated (${completion.usage?.total_tokens || 0} tokens)`);
            
            return {
                text: response,
                model: completion.model,
                tokens_used: completion.usage?.total_tokens || 0,
                prompt_tokens: completion.usage?.prompt_tokens || 0,
                completion_tokens: completion.usage?.completion_tokens || 0
            };
            
        } catch (error) {
            console.error('‚ùå OpenAI API error:', error);
            
            // Handle specific error types
            if (error.code === 'insufficient_quota') {
                throw new Error('OpenAI API quota exceeded');
            } else if (error.code === 'invalid_api_key') {
                throw new Error('Invalid OpenAI API key');
            } else if (error.code === 'model_not_found') {
                throw new Error('OpenAI model not found');
            }
            
            throw new Error(`OpenAI API error: ${error.message}`);
        }
    }
    
    // Generate product recommendation response
    static async generateProductResponse(products, query) {
        try {
            if (!this.isAvailable()) {
                return this.generateFallbackProductResponse(products, query);
            }
            
            const productList = products.map(p => 
                `- ${p.product_name}: ${p.price.toLocaleString('vi-VN')}ƒë`
            ).join('\n');
            
            const prompt = `Kh√°ch h√†ng t√¨m ki·∫øm "${query}" v√† t√¥i ƒë√£ t√¨m th·∫•y c√°c s·∫£n ph·∫©m sau:\n${productList}\n\nH√£y vi·∫øt m·ªôt ph·∫£n h·ªìi ng·∫Øn g·ªçn, th√¢n thi·ªán ƒë·ªÉ gi·ªõi thi·ªáu c√°c s·∫£n ph·∫©m n√†y.`;
            
            const response = await this.generateResponse({
                userMessage: prompt,
                intent: 'product',
                maxTokens: 300
            });
            
            return response.text;
            
        } catch (error) {
            console.error('‚ùå Product response error:', error);
            return this.generateFallbackProductResponse(products, query);
        }
    }
    
    // Generate order status response
    static async generateOrderResponse(order, orderId) {
        try {
            if (!this.isAvailable()) {
                return this.generateFallbackOrderResponse(order, orderId);
            }
            
            const orderInfo = `ƒê∆°n h√†ng #${order.id} - Tr·∫°ng th√°i: ${order.status} - T·ªïng ti·ªÅn: ${order.total_amount.toLocaleString('vi-VN')}ƒë - Ng√†y ƒë·∫∑t: ${new Date(order.created_at).toLocaleDateString('vi-VN')}`;
            
            const prompt = `Kh√°ch h√†ng h·ªèi v·ªÅ ƒë∆°n h√†ng "${orderId}". Th√¥ng tin ƒë∆°n h√†ng: ${orderInfo}\n\nH√£y vi·∫øt ph·∫£n h·ªìi th√¢n thi·ªán, cung c·∫•p th√¥ng tin ƒë∆°n h√†ng v√† h∆∞·ªõng d·∫´n ti·∫øp theo (n·∫øu c·∫ßn).`;
            
            const response = await this.generateResponse({
                userMessage: prompt,
                intent: 'order',
                maxTokens: 300
            });
            
            return response.text;
            
        } catch (error) {
            console.error('‚ùå Order response error:', error);
            return this.generateFallbackOrderResponse(order, orderId);
        }
    }
    
    // Fallback responses when OpenAI is not available
    static generateFallbackProductResponse(products, query) {
        if (products.length === 0) {
            return `Xin l·ªói, kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o cho "${query}". B·∫°n c√≥ th·ªÉ th·ª≠ t·ª´ kh√≥a kh√°c kh√¥ng? üîç`;
        }
        
        return `üõí T√¥i ƒë√£ t√¨m th·∫•y ${products.length} s·∫£n ph·∫©m ph√π h·ª£p v·ªõi "${query}"! \n\nB·∫°n c√≥ th·ªÉ xem chi ti·∫øt c√°c s·∫£n ph·∫©m b√™n d∆∞·ªõi. N·∫øu c·∫ßn t∆∞ v·∫•n th√™m, h√£y cho t√¥i bi·∫øt nh√©! üòä`;
    }
    
    static generateFallbackOrderResponse(order, orderId) {
        const statusMap = {
            'pending': 'ƒëang x·ª≠ l√Ω',
            'confirmed': 'ƒë√£ x√°c nh·∫≠n',
            'shipped': 'ƒëang v·∫≠n chuy·ªÉn',
            'delivered': 'ƒë√£ giao',
            'cancelled': 'ƒë√£ hu·ª∑'
        };
        
        const vietnameseStatus = statusMap[order.status] || order.status;
        
        return `üì¶ Th√¥ng tin ƒë∆°n h√†ng #${order.id}:\n\n` +
               `‚Ä¢ Tr·∫°ng th√°i: ${vietnameseStatus}\n` +
               `‚Ä¢ T·ªïng ti·ªÅn: ${order.total_amount.toLocaleString('vi-VN')}ƒë\n` +
               `‚Ä¢ Ng√†y ƒë·∫∑t: ${new Date(order.created_at).toLocaleDateString('vi-VN')}\n\n` +
               `B·∫°n c√≥ c√¢u h·ªèi g√¨ kh√°c v·ªÅ ƒë∆°n h√†ng kh√¥ng? üòä`;
    }
    
    // Get API usage statistics
    static async getUsageStats() {
        try {
            if (!this.isAvailable()) {
                return { available: false, message: 'OpenAI not configured' };
            }
            
            // Note: OpenAI doesn't provide real-time usage stats via API
            // This is a placeholder for future implementation
            return {
                available: true,
                model: process.env.OPENAI_MODEL || 'gpt-3.5-turbo',
                status: 'active'
            };
            
        } catch (error) {
            console.error('‚ùå OpenAI usage stats error:', error);
            return { available: false, error: error.message };
        }
    }
    
    // Test OpenAI connection
    static async testConnection() {
        try {
            if (!this.isAvailable()) {
                return { success: false, message: 'OpenAI API key not configured' };
            }
            
            const testResponse = await this.generateResponse({
                userMessage: 'Hello, please respond with "Test successful"',
                intent: 'general',
                maxTokens: 50
            });
            
            return {
                success: true,
                message: 'OpenAI connection successful',
                response: testResponse.text,
                model: testResponse.model
            };
            
        } catch (error) {
            return {
                success: false,
                message: 'OpenAI connection failed',
                error: error.message
            };
        }
    }
}

module.exports = OpenAIService;